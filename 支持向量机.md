#### 支持向量机SVM

主要用于**分类**问题，它的基本模型是定义在特征空间上的**间隔最大的线性分类器**；SVM还包括**核技巧**，这使它成为实质上的非线性分类器。SVM的的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。SVM的的学习算法就是求解凸二次规划的最优化算法。



##### 简单易懂的数学原理：

【引用】[通俗易懂举栗子--怎么理解支持向量机（SVM）？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/396646387)



##### sklearn库中svm函数

```python
import sklearn.svm as svm

clf = svm.SVC(C=1.0,
kernel='rbf', 
degree=3, 
gamma='auto',
coef0=0.0, 
shrinking=True,
probability=False,
tol=0.001, 
cache_size=200, c
lass_weight=None, 
verbose=False, 
max_iter=-1, 
decision_function_shape=None,
random_state=None)
```

【参数说明】：

- **C**：SVC的惩罚参数，默认值是1.0；**C越大**，对误分类的惩罚增大，趋向于对训练集完全分对的情况，这样对训练集准确率很高，但**泛化能力弱**。**C值小**，对误分类的惩罚减小，允许容错，将他们当成噪声点，**泛化能力较强**

- **kernel ：**核函数，默认是rbf，可以是‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’

  - linear：线性分类器（C越大分类效果越好，但有可能会过拟合（default C=1））

  - poly：多项式分类器

  - rbf：高斯模型分类器（gamma值越小，分类界面越连续；gamma值越大，分类界面越“散”，分类效果越好，但可能会过拟合）
  - sigmoid：sigmoid核函数

- degree ：多项式poly函数的维度，默认是3，选择其他核函数时会被忽略。

- gamma ： ‘rbf’,‘poly’ 和‘sigmoid’的核函数参数。默认是’auto’。 如果gamma是’auto’，那么实际系数是1 / n_features。

- coef0 ：核函数中的独立项。 它只在’poly’和’sigmoid’中很重要。

- probability ：是否启用概率估计。 必须在调用fit之前启用它，并且会减慢该方法的速度。默认为False

- shrinking ：是否采用shrinking heuristic方法(收缩启发式)，默认为true

- tol ：停止训练的误差值大小，默认为1e-3

- cache_size ：核函数cache缓存大小，默认为200

- class_weight ：类别的权重，字典形式传递。设置第几类的参数C为weight*C(C-SVC中的C)

- verbose ：允许冗余输出

- max_iter ：最大迭代次数。-1为无限制。

- decision_function_shape ：‘ovo’, ‘ovr’ or None, default=ovr

- 关于‘ovo’, ‘ovr’的解释：

  - 一对多法（one-versus-rest,简称OVR SVMs）：训练时依次把某个类别的样本归为一类,其他剩余的样本归为另一类，这样k个类别的样本就构造出了k个SVM。分类时将未知样本分类为具有最大分类函数值的那类。

  - 一对一法（one-versus-one,简称OVO SVMs或者pairwise）：其做法是在任意两类样本之间设计一个SVM，因此k个类别的样本就需要设计k(k-1)/2个SVM。当对一个未知样本进行分类时，最后得票最多的类别即为该未知样本的类别。



##### python代码实现

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import svm
from sklearn.datasets import make_blobs
from sklearn.model_selection import train_test_split

if __name__ == '__main__':
    #读取数据
    data = pd.read_csv('iris.csv')
    # 获取特征列
    x = data.iloc[:, : - 1]
    # 获取目标列
    y = data.iloc[:, -1]

    # 将数据集分为训练集和测试集
    x_train, x_test, y_train, y_test = train_test_split(x, y)

    # 构建一个内核为线性的支持向量机模型
    clf = svm.SVC(kernel='linear', C=10)

    # 训练模型
    clf.fit(x_train,y_train)

    #使用训练好的模型进行预测
    # x_to_test = [5.1, 3.5, 1.4, 0.2] #输入要预测的输入变量
    y_pred = clf.predict(x_test)
```

