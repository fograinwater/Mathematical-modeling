### 决策树 CART

[决策树（ID3、C4.5、CART）的原理、Python实现、Sklearn可视化和应用 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/339380585)

决策树是一种预测模型，同时也是一种树状结构，代表的是对象属性与对象值之间的一种映射关系。它的每一个叶节点对应着一个分类，非叶节点对应着在某个属性上的划分，根据样本在该属性上的不同取值将其划分成若干个子集。



### CART的基础概念

**【熵】**：物理意义是体系混乱程度的度量。

【**信息熵**】：事物不确定性的度量标准，可以根据数学中的概率计算，出现的概率就大，出现的机会就多，不确定性就小（信息熵小）

**计算：**对于二分类问题，考虑n个属性，第i个属性可能有ki个分支，那么对于每个属性，可以计算其每个分支的信息熵

<img src="https://raw.githubusercontent.com/fograinwater/PicGo-img/master/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-03%20224847.png" alt="屏幕截图 2023-06-03 224847" style="zoom:50%;" />

**【信息增益】：**在某一条件下，随机变量不确定性减少的程度，用于衡量一个**特征对于分类任务的贡献程度**。如果一个特征的信息增益越大，说明它对信息不确定性的减少程度贡献越大，说明它对决策树预测能力的影响越大，则它越应该作为优先决策结点。

**Gain(X,A) = Ent(X) - Ent(X|A)**

<img src="https://raw.githubusercontent.com/fograinwater/PicGo-img/master/image-20230710131801706.png" alt="image-20230710131801706" style="zoom: 67%;" />



**但是，**信息增益倾向于选择分支多的属性，容易导致过拟合，需要施以“**惩罚”，解决办法：**

**【增益率Gain-ratio】:** 对信息增益进行修正，考虑了特征的分支数量。仍然选择较大的作为优先考虑的分支属性。

<img src="https://raw.githubusercontent.com/fograinwater/PicGo-img/master/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-04%20103820.png" alt="屏幕截图 2023-06-04 103820" style="zoom: 50%;" />

其中

<img src="https://raw.githubusercontent.com/fograinwater/PicGo-img/master/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-04%20103834.png" alt="屏幕截图 2023-06-04 103834" style="zoom:50%;" />

所以对于每个属性，其基尼系数为分支划分后，各个分支的基尼系数以分支概率为权重进行加和：

<img src="https://raw.githubusercontent.com/fograinwater/PicGo-img/master/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202023-06-04%20105422.png" alt="屏幕截图 2023-06-04 105422" style="zoom:50%;" />



### CART原理

<img src="https://raw.githubusercontent.com/fograinwater/PicGo-img/master/image-20230730210735746.png" alt="image-20230730210735746" style="zoom:67%;" />



<img src="https://raw.githubusercontent.com/fograinwater/PicGo-img/master/image-20230730215022437.png" alt="image-20230730215022437" style="zoom:67%;" />

<img src="https://raw.githubusercontent.com/fograinwater/PicGo-img/master/image-20230730210710650.png" alt="image-20230730210710650" style="zoom:67%;" />

**【3种典型的决策树算法的比较】**

<img src="https://raw.githubusercontent.com/fograinwater/PicGo-img/master/image-20230710114039835.png" alt="image-20230710114039835" style="zoom:67%;" />



#### 使用sklearn构建决策树

决策树--模块：sklearn.tree

- **tree.DecisionTreeClassifier	分类树**

  参数：

  - class_weight ： 指定样本各类别的的权重.

  - criterion ：决定不纯度的计算方法。gini或者entropy，默认为gini，前者是基尼系数(CART)，后者是信息熵(ID3)；

    ```
    比起基尼系数，信息熵对不纯度更加敏感，对不纯度的惩罚最强。但在实际使用中，信息熵和基尼系数的效果基本相同。
    同时，因为信息熵对不纯度更加敏感，所以信息熵作为指标时，决策树的生长会更加“精细”,因此对于高维数据或者噪音很多的数据，信息熵很容易过拟合，基尼系数在这种情况下效果往往会更好。
    ```

  - max_depth（剪枝参数） ：(default=None) 决策树的最大深度，深度越大越容易过拟合，推荐树的深度为：5-20之间

  - random_state & splitter：设置分支中的随机模式的参数，默认为None，在高维度时随机性会表示的更加明显。

- **tree.DecisionTreeRegressor	回归树**

tree.export_graphviz	将生成的决策树导出为DOT模式，画图专用

tree.ExtraTreeClassifier	高随机版本的分类树

tree.ExtraTreeRegressor	高随机版本的回归树



#### CART分类树

```python
# 1.读入数据，把Name列取出来作为标签（groundtruth）
import pandas as pd
data = pd.read_csv('fishiris.csv')
# print(data.head(5))
X = data.iloc[:, data.columns != 'Name']
Y = data['Name'] 

# 2.分割验证集和训练集
from sklearn.model_selection import train_test_split
Xtrain, Xtest, Ytrain, Ytest = train_test_split(X,Y,test_size=0.2)

# 导入分类树的模块
from sklearn.tree import DecisionTreeClassifier

# 创建并训练CART决策树
clf = DecisionTreeClassifier(random_state=3) # 实例化
clf = clf.fit(Xtrain,Ytrain) # 拟合训练
score_ = clf.score(Xtest, Ytest) # 导入测试集查看得分

# 可以输入数据送到训练好的模型里，输出预测的类
y_pred = clf.predict(Xtest)
```



#### ID3分类树+可视化

##### 1.ID3分类树：信息增益特征选择

缺点：

- ID3 没有剪枝策略，容易过拟合；
- 信息增益准则对可取值数目较多的特征有所偏好，类似“编号”的特征其信息增益接近于 1；
- 只能用于处理离散分布的特征；
- 没有考虑缺失值。

```python
"""
@des：基于 sklearn 实现 ID3 分类树的预测、可视化
"""
import pandas as pd
import sklearn.datasets as datasets
from sklearn.tree import DecisionTreeClassifier
import graphviz
from sklearn.tree import export_graphviz
# 以下这两行是手动进行环境变量配置，防止在本机的环境变量部署失败
import os
os.environ['PATH'] = os.pathsep + r'D:\Program Files\Graphviz2.38\bin'

# 构建决策树模型（ID3分类树，信息增益特征选择）
iris = datasets.load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
y = iris.target
dtree = DecisionTreeClassifier(criterion='entropy', max_depth=3) 
dtree.fit(df, y)

# 使用export_graphviz方法生成dot_data文件
dot_data = export_graphviz(dtree, out_file=None, filled=True, rounded=True,
                           special_characters=True, feature_names=iris.feature_names,
                           class_names=['山鸢尾（Setosa）','变色鸢尾（Versicolor）','维吉尼亚鸢尾（Virginical）'],
                           leaves_parallel=True)

# 生成决策树的可视化文件
# 如果feature_name和class_name都不包含中文，使用方法1
# === 方法1 ===
graph = graphviz.Source(dot_data)
graph.render("iris_decision_tree")  # 保存图像为PDF文件，可选
graph.view()  # 在系统默认的图像查看器中显示决策树图像

# 如果feature_name和class_name包含中文，使用方法2
# === 方法2 ===
# 1.将dot_data写入到txt文件中
f = open('dot_data.txt', 'w')
f.write(dot_data)
f.close()

# 2.修改原来dot_data.txt中的字体及编码格式，并将其另存为一个新的dot_data_new.txt文件
import re
f_old = open('dot_data.txt', 'r')
f_new = open('dot_data_new.txt', 'w', encoding='utf-8')
for line in f_old:
    if 'fontname' in line:
        font_re = 'fontname=(.*?)]'
        old_font = re.findall(font_re, line)[0]
        line = line.replace(old_font, 'SimHei')
    f_new.write(line)
f_old.close()
f_new.close()

# 3.调用os.system系统函数来使用graphviz插件从而生成可视化文件
# -Tpdf表示生成PDF格式的文件，-Tpng表示生成PNG格式的图片文件
os.system('dot -Tpdf dot_data_new.txt -o 决策树模型.pdf')
# os.system('dot -Tpng dot_data_new.txt -o 决策树模型.png')
```

- **可视化结果**

![image-20230730210349515](https://raw.githubusercontent.com/fograinwater/PicGo-img/master/image-20230730210349515.png)



【附】：

##### export_graphviz的参数含义

`export_graphviz`函数是用于将决策树导出为DOT格式的字符串，方便后续通过GraphViz库可视化决策树。以下是`export_graphviz`函数的各参数含义：

- `decision_tree`: 必需参数，指定决策树模型。
- `out_file`: 将DOT格式的决策树保存到文件中，可以是文件名或文件句柄。默认为`None`，表示不保存到文件，而是返回生成的DOT格式字符串。
- `max_depth`: 决策树的最大深度。默认为`None`，表示不限制最大深度。
- `feature_names`: 特征名称列表，指定特征的名称。如果提供，节点将使用特征的名称来标识，否则将使用特征索引。
- `class_names`: 类别名称列表，指定类别的名称。如果提供，叶节点将使用类别名称来标识，否则将使用类别的数值。
- `filled`: 是否为每个节点填充颜色，表示节点的类别纯度。默认为`False`。
- `rounded`: 是否将节点框边角变为圆角。默认为`False`。
- `special_characters`: 是否使用HTML或特殊字符来表示节点的标签。默认为`False`。
- `precision`: 小数点后保留的位数。默认为`3`。
- `leaves_parallel`: 是否将叶节点并行排列。默认为`False`。
- `rotate`: 是否旋转节点的标签。默认为`False`。
- `label`: 是否在节点上显示标签。默认为`None`，表示显示节点的`value`参数（类别计数）。
- `impurity`: 是否在节点上显示不纯度。默认为`None`，表示显示节点的`gini`参数（基尼不纯度）。
- `node_ids`: 是否在节点上显示节点的ID。默认为`False`。
- `proportion`: 是否在节点上显示类别的样本占比。默认为`False`。
- `rotate`: 是否旋转节点的标签。默认为`False`。
- `out_file`: 将DOT格式的决策树保存到文件中，可以是文件名或文件句柄。默认为`None`，表示不保存到文件，而是返回生成的DOT格式字符串。

除了以上参数外，`export_graphviz`函数还支持其他一些参数，但这些参数通常用于更高级的定制化需求，一般情况下并不需要进行设置。



##### 使用`graphviz`库将决策树可视化后，各参数的含义：

1. **样本数量（sample）**：在决策树节点中，显示该节点上对应的样本数量。例如，`sample = 50`表示该节点上有50个样本。

2. **类别计数（value）**：表示在当前节点中每个类别的样本数量。例如，`value = [45, 5]`表示在该节点中有45个属于类别1的样本，和5个属于类别2的样本。

3. **基尼不纯度（gini）**：表示用于衡量节点不纯度的指标，基尼不纯度越低表示节点的纯度越高，节点上的样本属于同一类别的可能性越大。
   
4. **样本权重（weight）**：表示该节点中的样本权重，通常在样本不均衡问题中使用，权重和样本数量相关。

5. **特征名称（feature）**：显示该节点进行划分的特征名称。

6. **分割阈值（threshold）**：如果节点使用了连续特征进行划分，分割阈值表示划分的临界值。

7. **叶节点类别（class）**：只在叶节点显示，表示该叶节点所属的类别。

8. **叶节点纯度（class）**：在叶节点显示，表示叶节点的纯度，即该节点中样本属于同一类别的可能性。



#### CART 回归树

【原理】：

将原来自变量的区间**划分为若干个区间**，使得每个区间划分都能得到最小的方差。

<img src="https://raw.githubusercontent.com/fograinwater/PicGo-img/master/image-20230801195007298.png" alt="image-20230801195007298" style="zoom:70%;" />

<img src="https://raw.githubusercontent.com/fograinwater/PicGo-img/master/image-20230801195454569.png" alt="image-20230801195454569" style="zoom:50%;" />

```python
"""
@des：基于 sklearn 实现 CART 回归树的预测、可视化
"""
import numpy as np
from pydotplus import graphviz
from sklearn.tree import DecisionTreeRegressor

X = np.arange(1, 11).reshape(-1, 1)
y = np.array([5.56, 5.70, 5.91, 6.40, 6.80, 7.05, 8.90, 8.70, 9.00, 9.05])

tree = DecisionTreeRegressor(max_depth=4).fit(X, y)

from six import StringIO
from IPython.display import Image
from sklearn.tree import export_graphviz
import pydotplus

dot_data = export_graphviz(tree, out_file=None,
                filled=True, rounded=True,
                special_characters=True,
                precision=2)

# 生成决策树的可视化文件
# 如果feature_name和class_name包含中文，使用方法2
# 1.将dot_data写入到txt文件中
f = open('dot_data.txt', 'w')
f.write(dot_data)
f.close()

# 2.修改原来dot_data.txt中的字体及编码格式，并将其另存为一个新的dot_data_new.txt文件
import re
f_old = open('dot_data.txt', 'r')
f_new = open('dot_data_new.txt', 'w', encoding='utf-8')
for line in f_old:
    if 'fontname' in line:
        font_re = 'fontname=(.*?)]'
        old_font = re.findall(font_re, line)[0]
        line = line.replace(old_font, 'SimHei')
    f_new.write(line)
f_old.close()
f_new.close()

# 3.调用os.system系统函数来使用graphviz插件从而生成可视化文件
# -Tpdf表示生成PDF格式的文件，-Tpng表示生成PNG格式的图片文件
import os
os.system('dot -Tpdf dot_data_new.txt -o 决策树模型.pdf')
# os.system('dot -Tpng dot_data_new.txt -o 决策树模型.png')
```

【可视化结果】：

![image-20230801195155321](https://raw.githubusercontent.com/fograinwater/PicGo-img/master/image-20230801195155321.png)
